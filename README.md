# AI_Driven_Harmful_Language_Detection_System
This project is an AI-powered harmful language detection system designed to operate across two primary interfaces:

🔹 Chat Interface – A web-based chat platform that analyzes messages in real-time to detect toxicity.

🔹 Discord Bot – An intelligent moderation bot for Discord servers that identifies and manages harmful messages automatically.

At the core of the system is the Unary Toxic BERT model, a deep learning-based NLP model specifically trained to detect offensive and harmful language. It processes incoming text and classifies it based on toxicity levels, triggering appropriate moderation actions such as flagging, warning, muting, or kicking users.

🚀 Key Features

✅ AI-driven analysis for detecting harmful and toxic content
✅ Real-time toxicity detection through the Chat Interface
✅ Automated moderation for Discord servers
✅ Emoji filtering to catch offensive symbols
✅ Dynamic actions like warnings, muting, and kicking based on toxicity scores
✅ Continuous deployment using Replit + Uptime Bot for 24/7 operation

⚠️ Important Note
This project includes a list of harmful words and phrases solely for detection and filtering purposes. These are essential for the AI model to function effectively and are not meant for offensive use.

🔗 Test It Out

🌐 Chat Interface: https://ai-harmful-language-frontend.onrender.com/
🤖 Discord Bot Invite: https://discord.gg/qEFhZtf4

