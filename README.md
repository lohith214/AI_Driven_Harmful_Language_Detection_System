# AI_Driven_Harmful_Language_Detection_System
This project is an AI-powered harmful language detection system designed to operate across two primary interfaces:

ğŸ”¹ Chat Interface â€“ A web-based chat platform that analyzes messages in real-time to detect toxicity.

ğŸ”¹ Discord Bot â€“ An intelligent moderation bot for Discord servers that identifies and manages harmful messages automatically.

At the core of the system is the Unary Toxic BERT model, a deep learning-based NLP model specifically trained to detect offensive and harmful language. It processes incoming text and classifies it based on toxicity levels, triggering appropriate moderation actions such as flagging, warning, muting, or kicking users.

ğŸš€ Key Features

âœ… AI-driven analysis for detecting harmful and toxic content
âœ… Real-time toxicity detection through the Chat Interface
âœ… Automated moderation for Discord servers
âœ… Emoji filtering to catch offensive symbols
âœ… Dynamic actions like warnings, muting, and kicking based on toxicity scores
âœ… Continuous deployment using Replit + Uptime Bot for 24/7 operation

âš ï¸ Important Note
This project includes a list of harmful words and phrases solely for detection and filtering purposes. These are essential for the AI model to function effectively and are not meant for offensive use.

ğŸ”— Test It Out

ğŸŒ Chat Interface: https://ai-harmful-language-frontend.onrender.com/
ğŸ¤– Discord Bot Invite: https://discord.gg/qEFhZtf4

